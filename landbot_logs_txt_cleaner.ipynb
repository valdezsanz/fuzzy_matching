{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_iu2MzSrSdbE4tmg7SJY_4kMRu2jF0_d",
      "authorship_tag": "ABX9TyPz1JZhEamQA1k7Nq1UYF0F"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# install libraries"
      ],
      "metadata": {
        "id": "J2qFAMgNFBh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#instll this library - read the doc \n",
        "!pip install fuzzywuzzy"
      ],
      "metadata": {
        "id": "-H0H3cqD36SL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein # install this to make fuzzy matching faster"
      ],
      "metadata": {
        "id": "Y7mlfEIWX-Wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "AdG2IDI3I2x1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "#Impor regex\n",
        "import re\n",
        "\n",
        "#Import csv\n",
        "import csv\n",
        "\n",
        "from IPython.utils.text import strip_email_quotes\n",
        "\n",
        "from fuzzywuzzy import process, fuzz"
      ],
      "metadata": {
        "id": "JCxkNrOAJa0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choose folder to work on "
      ],
      "metadata": {
        "id": "znTZU_P1Jjx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Insert the folder you are working on (e.g. folder = '18 Living with Social Media') and the VCS number (e.g. vcs_number = '18')\n",
        "\n",
        "folder = '21 Achieving Peak Performance'\n",
        "vcs_number = '21'"
      ],
      "metadata": {
        "id": "JLHcSAVdJogb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### set up working directory"
      ],
      "metadata": {
        "id": "EidI8MTPJA4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Connecting with Gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Import Module\n",
        "import os\n",
        "  \n",
        "# Folder Path\n",
        "path = f'/content/drive/My Drive/ SV9001 Landbot data extraction automation/{folder}'\n",
        "\n",
        "# Change the directory\n",
        "os.chdir(path)"
      ],
      "metadata": {
        "id": "5R6608uHJhoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question - answers from users "
      ],
      "metadata": {
        "id": "E9JdDCcE_sqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Clean .txt files  "
      ],
      "metadata": {
        "id": "oERJXZnU-e18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get a list of txt files inside the folder :\n",
        "def file_list():\n",
        "  global file_path_list\n",
        "  file_path_list=[] \n",
        "  ## iterate through all files\n",
        "  for file in os.listdir():\n",
        "      # Check whether file is in text format or not\n",
        "      if file.endswith('.txt'):\n",
        "          file_path = f\"{path}/{file}\"\n",
        "          file_path_list.append(file_path)"
      ],
      "metadata": {
        "id": "ts92mTyNMYlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ignore_files_cleaned():\n",
        "    global log_files_cleaned\n",
        "    log_files_cleaned=[]# set to empty\n",
        "    global file_path_list # set this variable to global \n",
        "    file_path = 'log_files_cleaned.csv'\n",
        "\n",
        "    try:\n",
        "        # Load the list from the CSV file\n",
        "        with open(file_path, 'r') as csvfile:\n",
        "            reader = csv.reader(csvfile)\n",
        "            log_files_cleaned = list(reader)[0]\n",
        "\n",
        "    #if the file is not found        \n",
        "    except FileNotFoundError:\n",
        "        print(f\"File '{file_path}' not found.THIS MIGHT BE THE FIRST TIME FILES ARE CLEANED\\n ALL .txt FILES WILL BE LOADED\")\n",
        "\n",
        "    # remove elements from file_path_list that were already cleaned\n",
        "    file_path_list = [x for x in file_path_list if x not in log_files_cleaned]"
      ],
      "metadata": {
        "id": "CJPtlZAivXMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## FUNCTION opens a file, iterates over each line in the file, removes the newline character from each line, and appends the modified lines to a list.\n",
        "\n",
        "def generate_script(file_path): \n",
        "  global script\n",
        "  script=[] ## set script to empty\n",
        "  with open(file_path, 'r') as f:\n",
        "    for line in f:\n",
        "      # remove newline character\n",
        "      clean_line=line.rstrip('\\n')\n",
        "      #check if line is empty\n",
        "      if clean_line !='':\n",
        "         # append to list \n",
        "        script.append(clean_line)  "
      ],
      "metadata": {
        "id": "LR5IFSlyMc3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#write log_files_cleaned to csv \n",
        "def write_list(l):\n",
        "  file_path = 'log_files_cleaned.csv'  # Path to the output CSV file\n",
        "  \n",
        "   # Save the list to a CSV file\n",
        "  with open(file_path, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(l)"
      ],
      "metadata": {
        "id": "2puhRsr1trKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Search for Question-Answer line with regex  "
      ],
      "metadata": {
        "id": "EdbXcMvTPiK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Searching for questions & answers rows:\n",
        "#If you print script you will notice that the rows with the questions, will be preceded by a ### 2022/07/05 06:45:00 | 18 Living with Social Media (Complete) ###; \n",
        "# and the answers row will be always be preceded by a ### 2022/07/05 06:44:58 | Visitor #189139665 ### hence the regular expression. \n",
        "\n",
        "def extract_q_a():\n",
        "  global regexq\n",
        "  global regexa\n",
        "  global q_a\n",
        "  global q_a_clean\n",
        "  global first_match\n",
        "  q_a=[] ## set q_a to empty \n",
        "  q_a_clean = [] ## set to empty \n",
        "  regexq = re.compile(r'\\W{3}\\s\\d{4}\\W\\d{2}\\W\\d{2}\\s\\d{2}\\W\\d{2}\\W\\d{2}\\s\\W\\s\\d')  #Regular expression to signal a question row.\n",
        "  regexa = re.compile(r'\\W{3}\\s\\d{4}\\W\\d{2}\\W\\d{2}\\s\\d{2}\\W\\d{2}\\W\\d{2}\\s\\W\\sVisitor') #Regular expression to signal a answer row.\n",
        "\n",
        "  ### WE WILL ONLY START COUNTING AFTER THE FIRST QUESTION. TO AVOID THOSE LINES  WHEN A CHAT STARTS SUCH AS ('hello holi')\n",
        "\n",
        "  first_match = False  # Flag to track the first match of regexq\n",
        "\n",
        "  for index, row in enumerate(script):\n",
        "      if not first_match and re.match(regexq, row):\n",
        "          first_match = True  # Set the flag to True after the first match\n",
        "\n",
        "      #if the line is a question :\n",
        "      if first_match and re.match(regexq, row):\n",
        "          q_a.append(row[4:23].strip()) # remove extra word and non word character\n",
        "          q_a.append(script[index+1].strip())#The question or the answer, will be always next of the row with the regex.\n",
        "\n",
        "      # if the line is an answer:\n",
        "      if first_match and  re.match(regexa, row):\n",
        "          q_a.append(row[35:45].strip()) # remove extra word and non word character\n",
        "          q_a.append(script[index+1].strip()) #The question or the answer, will be always next of the row with the regex.\n",
        "          \n",
        "          # if the text of the row is an answer,we want to retrieve both the question and the answer:\n",
        "          # generate list of lists [date,question,user,answer] \n",
        "          q_a_clean.append(q_a[-4:])  #We are creating a list of list with date, question, user number and answer)\n"
      ],
      "metadata": {
        "id": "FXIc799kCC42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterating over all the txt files in the folder "
      ],
      "metadata": {
        "id": "TpmnJ-8jlsrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_list() # returns a list of files (file_path_list)\n",
        "ignore_files_cleaned() # returns (file_path_list) after removing the paths that were inside log_of_files_cleaned. if it exists\n",
        "\n",
        "#file_path_list #check the list returned\n",
        "\n",
        "df_q_a=pd.DataFrame()\n",
        "\n",
        "#loop over the list of files \n",
        "\n",
        "for file_path in (file_path_list):\n",
        "  generate_script(file_path) # returns all the conversation (script)\n",
        "  #add path to the log\n",
        "  log_files_cleaned.append(file_path) \n",
        "\n",
        "  extract_q_a() # returns questions and answers  (q_a) and q_a_clean\n",
        "  \n",
        "  #write q_a_clean to a dataframe \n",
        "  # Create a temporary DataFrame for the current iteration's list\n",
        "  temp_df = pd.DataFrame(q_a_clean, columns =['created_at', 'question','user_number','answer'])\n",
        "\n",
        "  # concat the temporary DataFrame to the main DataFrame\n",
        "  df_q_a = pd.concat([df_q_a,temp_df], ignore_index=True)\n",
        "\n",
        "\n",
        "#write the list of file_path to the log in .csv\n",
        "write_list(log_files_cleaned)"
      ],
      "metadata": {
        "id": "9wqDMBYIzbIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CHECKPOINT questions-answers"
      ],
      "metadata": {
        "id": "jIQ_gDee_HD_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save  Cleaned questions-answers  DataFrame"
      ],
      "metadata": {
        "id": "MmwEhmkj-JjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save dataframe (UNCOMENT THIS FOR SAVING )\n",
        "\n",
        "#df_q_a.to_csv(f'/content/drive/My Drive/ SV9001 Landbot data extraction automation/{folder}/data_processed/vcs{vcs_number}_test_nahuel.csv')"
      ],
      "metadata": {
        "id": "8FsL1LII-Vhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read saved  questions-answers DataFrame"
      ],
      "metadata": {
        "id": "Mc1T2uxjPxV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read saved dataFrame \n",
        "\n",
        "# Specify the file path\n",
        "file_path = (f'/content/drive/My Drive/ SV9001 Landbot data extraction automation/{folder}/data_processed/vcs{vcs_number}_test_nahuel.csv')\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df_q_a = pd.read_csv(file_path,index_col=0)\n",
        "\n",
        "#remove trailing '.' from questions and andswers \n",
        "df_q_a['question']=df_q_a['question'].str.rstrip('. !')\n",
        "df_q_a['answer']=df_q_a['answer'].str.rstrip('. !')"
      ],
      "metadata": {
        "id": "FMd0BjlrPs8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can use a list of questions to filter by "
      ],
      "metadata": {
        "id": "cloNCO8qgKye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_list=[]"
      ],
      "metadata": {
        "id": "AesDAIMKgQP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Users data ( email-user number) "
      ],
      "metadata": {
        "id": "pFkhmbvE_yoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "make sure there is a .csv file in data processed with the name:\n",
        "\n",
        "VCS{vcs_number}_users_db.csv\n",
        "\n",
        "columns: @email , @id"
      ],
      "metadata": {
        "id": "MuAvMJLa_74G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read users data "
      ],
      "metadata": {
        "id": "nF6dvVU0lRaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing user's info from Drive\n",
        "users = pd.read_csv(f'/content/drive/My Drive/ SV9001 Landbot data extraction automation/{folder}/data_processed/VCS{vcs_number}_users_db.csv')\n",
        "\n",
        "users.rename(columns = {'@email':'user_email', '@id':'user_number'}, inplace = True)\n",
        "\n",
        "users['user_number']=users['user_number'].astype(int)"
      ],
      "metadata": {
        "id": "kdpTsqYXkprR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Join questions-answer to user data "
      ],
      "metadata": {
        "id": "r_iNc-LYlegq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# set user_number as string \n",
        "#df_q_a['user_number'] = df_q_a['user_number'].str.replace(r'[^0-9]', '',regex=True) ##uncoment or coment this as needed \n",
        "df_q_a['user_number'] = df_q_a['user_number'].astype(int)"
      ],
      "metadata": {
        "id": "0y9VlxcQlje8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merging both dataframes\n",
        "all_data = df_q_a.merge(users, on = 'user_number')"
      ],
      "metadata": {
        "id": "kVNsc8VT_ihI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data.sort_values('created_at',ascending=False)"
      ],
      "metadata": {
        "id": "fheApHUjlmNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question - Catalogue "
      ],
      "metadata": {
        "id": "YAz42epwAWSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "make sure there is a .csv file in data processed with the name:\n",
        "\n",
        "question_catalogue\n",
        "\n",
        "columns: question_v1 , answers_v1 ,\ttype , reverse_answer? [yes/no]\n",
        "\n",
        "* in the column answers in the excel file . REPLACE a) b) c) etc with 1,2,3 etc .\n",
        "\n",
        "* fill in wich health tracking questions are reverse or not: **If 1 is good > reverse = yes** \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p6QkJYy6AZOS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read question_catalogue file "
      ],
      "metadata": {
        "id": "maX1zpWWwRvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read question_catalogue\n",
        "# Specify the file path\n",
        "file_path = (f'/content/drive/My Drive/ SV9001 Landbot data extraction automation/{folder}/data_processed/question_catalogue.csv')\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "question_catalogue = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "ajm5iOJKmx2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_catalogue.head(5)"
      ],
      "metadata": {
        "id": "E67R6_upwmL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean question_catalogue"
      ],
      "metadata": {
        "id": "xPgaUw_zwCP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split answer column by \\n\n",
        "question_catalogue['answers_v1'] = question_catalogue['answers_v1'].apply(lambda x: x.split('\\n'))\n",
        "\n",
        "#remove blank and empty strings \n",
        "question_catalogue['answers_v1'] = question_catalogue['answers_v1'].apply(lambda x: [item.strip() for item in x if item.strip()])\n",
        "\n",
        "# separate answers into different rows \n",
        "question_catalogue=question_catalogue.explode('answers_v1')\n",
        "\n",
        "# separate number from text into different columns \n",
        "question_catalogue[['answer_number', 'answer_text']] = question_catalogue['answers_v1'].str.extract(r'(\\d+)(.*)')\n",
        "\n",
        "#remove trailing '.' from  answers \n",
        "question_catalogue['answer_text']=question_catalogue['answer_text'].str.strip('. !')\n",
        "\n",
        "#remove trailing \\r from questions \n",
        "question_catalogue['question_v1']=question_catalogue['question_v1'].str.rstrip('\\r')\n",
        "\n",
        "#change data type of the answer_number column \n",
        "question_catalogue['answer_number'] = question_catalogue['answer_number'].astype(int)\n",
        "\n",
        "#change data type of the reverse_answer column \n",
        "question_catalogue.loc[:, 'reverse_answer? [yes/no]'] = question_catalogue['reverse_answer? [yes/no]'].astype(str)\n",
        "\n",
        "#remove trailing spaces \n",
        "\n",
        "question_catalogue.loc[:, 'reverse_answer? [yes/no]'] = question_catalogue['reverse_answer? [yes/no]'].str.strip(' ')"
      ],
      "metadata": {
        "id": "nmUy77261OwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check if there are null values, meaning the regex is wrong \n",
        "null_values = question_catalogue['answer_number'].isnull().sum() \n",
        "null_values"
      ],
      "metadata": {
        "id": "WhxznoPmtg00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change name of question_v1 column\n",
        "question_catalogue['question']=question_catalogue['question_v1']\n",
        "\n",
        "# create another dataframe with only the columns we care about \n",
        "question_catalogue_clean=question_catalogue[['question',\n",
        "                                            'answer_number',\n",
        "                                            'answer_text',\n",
        "                                            'type',\n",
        "                                            'reverse_answer? [yes/no]']]\n",
        "question_catalogue_clean.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "eVAqw2Owu-Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Health tracking answer values "
      ],
      "metadata": {
        "id": "ifixtXhpwGNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## SELECT HEALTH TRACKING AND BUILD THE LOGIC TO ASSING A VALUE DEPENDING ON THE ANSWER NUMBER,AND REVERSE SCALE AND THE SCALE OF 0 TO 10000"
      ],
      "metadata": {
        "id": "RSg5n7oT0Dnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter=question_catalogue_clean['type']=='Health Tracking'\n",
        "\n",
        "question_catalogue_clean[filter][['question','answer_number']].groupby('question').count()\n",
        "\n",
        "## here we see that all health tracking questions have 5 answers \n",
        "## every answer goes from 1 to 5 \n",
        "## if reverse=false 5=10000 and 1=0\n",
        "## if reverse=true 1=10000 and 5=0"
      ],
      "metadata": {
        "id": "PckWKzi92i8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#only health tracking has values in the reverse_answer column, there is no need to filter by type of question\n",
        "\n",
        "for index, row in question_catalogue_clean.iterrows():\n",
        "\n",
        "  reverse=question_catalogue_clean.loc[index,'reverse_answer? [yes/no]']\n",
        "\n",
        "  if reverse=='no':\n",
        "    question_catalogue_clean.loc[index,'answer_value']=(question_catalogue_clean.loc[index,'answer_number']-1)*2500\n",
        "  if reverse=='yes':\n",
        "    question_catalogue_clean.loc[index,'answer_value']=10000-(question_catalogue_clean.loc[index,'answer_number']-1)*2500\n",
        "\n",
        "\n",
        "## if reverse=no 5=10000 and 1=0\n",
        "## if reverse=yes 1=10000 and 5=0"
      ],
      "metadata": {
        "id": "vjbajCva3TJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "if reverse is false that means that for the answer score, 5 = 10000; 4=7500; 3=5000; 2=2500 and 1 = 0. If the reverse is true the scale change direction, so 1=10000 and start decreasing in steps of 2500 until 5=0.\n",
        "\n",
        "\n",
        "**If 1 is good > reverse = yes**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B9o6P5OOli2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check answer values \n",
        "\n",
        "question_catalogue_clean[filter]"
      ],
      "metadata": {
        "id": "aFBnZQWSGvte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Health literacy answer Values "
      ],
      "metadata": {
        "id": "OOd_2737wSDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filter=question_catalogue_clean['type']=='Health Literacy'\n",
        "\n",
        "question_catalogue_clean[filter][['question','answer_number']].groupby('question').count()\n",
        "\n",
        "## here we see that health literacy have a variable number of answer numbers \n",
        "## answer values can go from 0 to 1 . 1 being positive \n",
        "## there is no consistency in answer number and answer value. we will have to evaluate that case by case "
      ],
      "metadata": {
        "id": "ou1kIMoI2hpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# manually add the answer_value for all health literacy questions:\n",
        "filter=question_catalogue_clean['type']=='Health Literacy'\n",
        "\n",
        "# do you want to reset the health_literacy values?\n",
        "valid_inputs = ['Y', 'N','n','y']\n",
        "user_input = input('do you want to reset all answer_values from health_literacy ?\\n[Y/N]')\n",
        "\n",
        "while user_input not in valid_inputs:\n",
        "    print(\"Invalid input. Please enter Y or N.\")\n",
        "    user_input = input('do you want to reset all answer_values from health_literacy ?\\n[Y/N]')\n",
        "\n",
        "if user_input=='Y' or user_input=='y':\n",
        "  question_catalogue_clean.loc[filter, 'answer_value'] = None\n",
        "\n",
        "# Loop through each row in the DataFrame\n",
        "print('input 0 or 1 for this questions-answers')\n",
        "for index, row in question_catalogue_clean[filter].iterrows():\n",
        "    #if there is already a value for answer, go next \n",
        "    if pd.isnull(question_catalogue_clean.loc[index, 'answer_value']):\n",
        "      # Display the prompt with the value from the 'answer' column\n",
        "      user_input = input(row['question']+'\\n'+row['answer_text'] + \": \")\n",
        "    \n",
        "       # Update the 'value' column in the DataFrame\n",
        "      question_catalogue_clean.loc[index, 'answer_value'] = user_input\n",
        "    else:\n",
        "      continue\n",
        "print('All answers already have a value !')"
      ],
      "metadata": {
        "id": "TGwoZf-U4dKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check values \n",
        "question_catalogue_clean[filter].head()"
      ],
      "metadata": {
        "id": "dYPOCdNowfjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Questions answer values "
      ],
      "metadata": {
        "id": "w1rMxKDUwbhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## all general questions should be 0 "
      ],
      "metadata": {
        "id": "c0XLMX2PxfJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter=question_catalogue_clean['type']=='General'\n",
        "\n",
        "question_catalogue_clean.loc[filter,'answer_value']=0"
      ],
      "metadata": {
        "id": "-gmV2oQaIJpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CHECKPOINT "
      ],
      "metadata": {
        "id": "-C-E5_Y5wjrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save cleaned question_catalogue"
      ],
      "metadata": {
        "id": "0INPFsYDBO-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check entire dataframe of question_catalogue \n",
        "question_catalogue_clean.head()"
      ],
      "metadata": {
        "id": "zDXzaac8IknX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save dataframe (UNCOMENT THIS TO SAVE)\n",
        "## question_catalogue_clean.to_csv(f'/content/drive/My Drive/ SV9001 Landbot data extraction automation/{folder}/data_processed/vcs{vcs_number}question_catalogue_clean.csv')"
      ],
      "metadata": {
        "id": "5bqjzEMKInSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read saved question_catalogue_clean"
      ],
      "metadata": {
        "id": "SnnnfZfX-8oP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read saved question_catalogue_clean dataFrame \n",
        "\n",
        "# Specify the file path\n",
        "file_path = (f'/content/drive/My Drive/ SV9001 Landbot data extraction automation/{folder}/data_processed/vcs{vcs_number}question_catalogue_clean.csv')\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "question_catalogue_clean = pd.read_csv(file_path,index_col=0)"
      ],
      "metadata": {
        "id": "RycrJyT5wv-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge similar Questions using matching scores \n"
      ],
      "metadata": {
        "id": "SHgFiPdcxfZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## questions from users "
      ],
      "metadata": {
        "id": "J6B0RBjHakvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check similarity of questions inside logs\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XssUequlFaFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check that all questions from the all_data dataframe are unique using fuzzy matching\n",
        "\n",
        "unique_questions=all_data[['question','answer']].groupby(['question']).count().sort_values('answer',ascending=False)\n",
        "unique_questions.rename(columns={'answer': 'answer_num'}, inplace=True)\n",
        "unique_questions.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "Fy-CKyFKyT9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_questions"
      ],
      "metadata": {
        "id": "Ql8cIqKbyUnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find similar string based on fuzzy matching and return similarity score\n",
        "def find_similar_string(string, choices):\n",
        "    choices = choices.drop(choices[choices == string].index)  # Exclude the string being evaluated\n",
        "    best_match = process.extractOne(string, choices, scorer=fuzz.token_sort_ratio)\n",
        "    if best_match is None or best_match[0] == string:\n",
        "        return \"\", 0  # Return empty string and similarity score of 0\n",
        "    else:\n",
        "        return best_match[0], best_match[1]  # Return best match string and similarity score\n",
        "\n",
        "# Apply fuzzy matching to create new columns for similar question, similarity score, and corresponding answer\n",
        "result = unique_questions['question'].apply(lambda x: find_similar_string(x, unique_questions['question']))\n",
        "unique_questions[['similar_question', 'similarity_score']] = pd.DataFrame(result.values.tolist(), index=result.index)\n",
        "\n",
        "# Add corresponding answer column based on similar_question\n",
        "unique_questions['similar_question_answer_num'] = unique_questions['similar_question'].map(unique_questions.set_index('question')['answer_num'])"
      ],
      "metadata": {
        "id": "D0kYBFVP4558"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add percentage of lost answers \n",
        "unique_questions['perc_dif_answers']=unique_questions['similar_question_answer_num']/unique_questions['answer_num']\n",
        "\n",
        "#filter by similarity of the questions \n",
        "filter_similarity=unique_questions['similarity_score']>70\n",
        "\n",
        "#filter by number of answers in the similar question\n",
        "filter_lost_answers=unique_questions['similar_question_answer_num']>10\n",
        "\n",
        "#filter by percentage of answers in the similar question\n",
        "filter_lost_perc=unique_questions['perc_dif_answers']>0.1\n",
        "\n",
        "#de-duplicate question - similar_question pairs \n",
        "filter_duplicate=unique_questions['answer_num']>unique_questions['similar_question_answer_num']\n",
        "\n",
        "\n",
        "unique_questions[filter_similarity&filter_lost_answers&filter_lost_perc&filter_duplicate].sort_values('similar_question_answer_num',ascending=False)"
      ],
      "metadata": {
        "id": "uyi8_Boh57xB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### make dict with replacements\n",
        "If no replacements are needed leave the dictionary empty \n"
      ],
      "metadata": {
        "id": "0THCl26EF7na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Format:\n",
        "\"\"\"\n",
        "replacements:{'similar_question':'question',\n",
        "              'similar_question':'question'}\n",
        "\"\"\"\n",
        "replacements={''}"
      ],
      "metadata": {
        "id": "ve9KZ4nKF9qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## create a new dataframe for the cleaned data \n",
        "all_data_cleaned=all_data\n",
        "\n",
        "## replace the questions using the dict :\n",
        "all_data_cleaned['question']=all_data['question'].replace(replacements)\n"
      ],
      "metadata": {
        "id": "G7-zogYhGmyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### check similarity with questions in the catalogue "
      ],
      "metadata": {
        "id": "ayTXNbSBO9G2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## make dataframe \n",
        "# Get unique questions from all_data_cleaned\n",
        "unique_questions_all_data = pd.DataFrame({'question': all_data_cleaned['question'].unique()})\n",
        "\n",
        "# Get unique questions from question_catalogue_clean\n",
        "unique_questions_question_catalogue = pd.DataFrame({'question': question_catalogue_clean['question'].unique()})"
      ],
      "metadata": {
        "id": "33rMvEiBPLSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find the most approximate match from df2 for a given question\n",
        "def find_approximate_match(question, df2_questions):\n",
        "    exact_matches = [q for q in df2_questions if q != question]  # Exclude exact matches\n",
        "    best_match = process.extractOne(question, exact_matches, scorer=fuzz.token_sort_ratio)\n",
        "    return best_match[0], best_match[1]\n",
        "\n",
        "# Load the two DataFrames\n",
        "df1 = unique_questions_all_data  # DataFrame 1 with questions\n",
        "df2 = unique_questions_question_catalogue # DataFrame 2 with questions\n",
        "\n",
        "# Get a list of questions and matching scores from df2\n",
        "df2_questions = df2['question'].tolist()\n",
        "\n",
        "# Apply fuzzy matching to find the most approximate match from df2 for each question in df1\n",
        "df1[['approximate_match', 'similarity_score']] = df1['question'].apply(lambda x: pd.Series(find_approximate_match(x, df2_questions)))\n",
        "\n",
        "# Create a new DataFrame with questions from df1, their most approximate matches from df2, and matching scores\n",
        "result_df = pd.DataFrame({'question_df1': df1['question'], 'approximate_match_df2': df1['approximate_match'], 'similarity_score': df1['similarity_score']})\n"
      ],
      "metadata": {
        "id": "9WPOPCOMRHAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "OS3NfkV9Sk4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filter by similarity of the questions \n",
        "filter_similarity=(result_df['similarity_score']>82)\n",
        "\n",
        "\n",
        "pd.set_option('display.max_colwidth', 150)\n",
        "\n",
        "result_df[filter_similarity].sort_values('similarity_score',ascending=False)\n"
      ],
      "metadata": {
        "id": "II6KcW1LRWEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### make the replacements\n",
        "The questions in the dataframe above are the ones that will be replaced.\n",
        "\n",
        "**Change filter_similarity until the dataframe only has the questions we want replaced**\n"
      ],
      "metadata": {
        "id": "uzjkdqdBYQrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select replacements :\n",
        "replacements_df=result_df[filter_similarity].sort_values('similarity_score',ascending=False)\n",
        "\n",
        "# Convert DataFrame to dictionary\n",
        "replacements = dict(zip(replacements_df['question_df1'], replacements_df['approximate_match_df2']))\n",
        "\n",
        "## replace the questions using the dict :\n",
        "all_data_cleaned['question']=all_data['question'].replace(replacements)"
      ],
      "metadata": {
        "id": "1V-3eg5dYK_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check dataframe \n",
        "all_data_cleaned.head()"
      ],
      "metadata": {
        "id": "sqdp-V64YPsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cleaned dataframe for all_data "
      ],
      "metadata": {
        "id": "g6-HuG20H1W6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check the dataframe \n",
        "all_data_cleaned"
      ],
      "metadata": {
        "id": "_T5gZSyMHQHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answers from users "
      ],
      "metadata": {
        "id": "pFWusrnoa8u4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### check similarity of answers inside logs "
      ],
      "metadata": {
        "id": "qB5b7cv7bAQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check that all answers from the all_data_cleaned dataframe are unique using fuzzy matching\n",
        "\n",
        "unique_answers=all_data_cleaned[['question','answer']].groupby(['answer']).count().sort_values('question',ascending=False)\n",
        "unique_answers.rename(columns={'question': 'question_num'}, inplace=True)\n",
        "unique_answers.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "0fY83Rb4bwcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_answers"
      ],
      "metadata": {
        "id": "cJCyLX_Kbwcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find similar string based on fuzzy matching and return similarity score\n",
        "def find_similar_string(string, choices):\n",
        "    choices = choices.drop(choices[choices == string].index)  # Exclude the string being evaluated\n",
        "    best_match = process.extractOne(string, choices, scorer=fuzz.token_sort_ratio)\n",
        "    if best_match is None or best_match[0] == string:\n",
        "        return \"\", 0  # Return empty string and similarity score of 0\n",
        "    else:\n",
        "        return best_match[0], best_match[1]  # Return best match string and similarity score\n",
        "\n",
        "# Apply fuzzy matching to create new columns for similar question, similarity score, and corresponding answer\n",
        "result = unique_answers['answer'].apply(lambda x: find_similar_string(x, unique_answers['answer']))\n",
        "unique_answers[['similar_answer', 'similarity_score']] = pd.DataFrame(result.values.tolist(), index=result.index)\n",
        "\n",
        "# Add corresponding answer column based on similar_question\n",
        "unique_answers['similar_answer_question_num'] = unique_answers['similar_answer'].map(unique_answers.set_index('answer')['question_num'])"
      ],
      "metadata": {
        "id": "e7QBmt4Qbwcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#add percentage of lost questions\n",
        "unique_answers['perc_dif_questions']=unique_answers['similar_answer_question_num']/unique_answers['question_num']\n",
        "\n",
        "#filter by similarity of the questions \n",
        "filter_similarity=unique_answers['similarity_score']>80\n",
        "\n",
        "#filter by number of answers in the similar question\n",
        "filter_lost_answers=unique_answers['similar_answer_question_num']>10\n",
        "\n",
        "#filter by percentage of answers in the similar question\n",
        "filter_lost_perc=unique_answers['perc_dif_questions']>0.1\n",
        "\n",
        "#de-duplicate question - similar_question pairs \n",
        "filter_duplicate=unique_answers['question_num']>unique_answers['similar_answer_question_num']\n",
        "\n",
        "\n",
        "unique_answers[filter_similarity&filter_lost_answers&filter_lost_perc&filter_duplicate].sort_values('similar_answer_question_num',ascending=False)"
      ],
      "metadata": {
        "id": "jG1o8J5Mbwcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **make a dict with the replacements**\n",
        "If no replacements are needed leave the dictionary empty \n"
      ],
      "metadata": {
        "id": "MTWtU_y-bGm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Format:\n",
        "\"\"\"\n",
        "replacements:{'similar_answer':'answer',\n",
        "              'similar_answer':'answer'}\n",
        "\"\"\"\n",
        "replacements={'':''}"
      ],
      "metadata": {
        "id": "lik7cGnrdX0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## replace the questions using the dict :\n",
        "all_data_cleaned['question']=all_data['question'].replace(replacements)"
      ],
      "metadata": {
        "id": "fjwNcGImdX0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check dataframe \n",
        "all_data_cleaned.head()"
      ],
      "metadata": {
        "id": "CB7GTNGGizwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Join dataframes: all_data to question_catalogue "
      ],
      "metadata": {
        "id": "WQkkDVBifpZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter all_data "
      ],
      "metadata": {
        "id": "diEXirSTDueY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#only keep questions from the log that are in the question catalogue \n",
        "filter=all_data_cleaned['question'].isin(question_catalogue_clean['question'].tolist())\n",
        "all_data_cleaned=all_data_cleaned[filter]"
      ],
      "metadata": {
        "id": "VQ2n79yKIpwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding best match for answers \n",
        "\n"
      ],
      "metadata": {
        "id": "wZIizy4IfVOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This block of code works like this :\n",
        "\n",
        "# For each row in the all_data_cleaned dataframe : ( wich is where we have the question logs and users data )\n",
        "# Select the question and the answer given by the user\n",
        "# Filters the question_catalogue to only show the answers for that question\n",
        "# Search for an exact match between the answer given by the user and the posible answers for that question in the question_catalogue\n",
        "# If a match is found : it writes it to the 'best_match' column \n",
        "# if a match is not found : we search for the best possible match in that subset  of posible answers to the question\n",
        "# then  write the best match, together with its matching score  to 'best_match' and 'match_score'column\n",
        "\n",
        "# at the end we need to filter the dataframe to save only high matching scores and exact matches.\n",
        "\n",
        "# Create columns \n",
        "all_data_cleaned['best_match'] = None\n",
        "all_data_cleaned['match_score'] = None\n",
        "\n",
        "# Loop through each row in the DataFrame\n",
        "for index, row in all_data_cleaned.iterrows():\n",
        "\n",
        "    # Function to find the closest match\n",
        "    def find_closest_match(query, choices):\n",
        "        best_match = process.extractOne(query, choices, scorer=fuzz.token_sort_ratio)\n",
        "        return best_match\n",
        "\n",
        "    # Select the question value\n",
        "    question = all_data_cleaned.loc[index, 'question']\n",
        "\n",
        "    # Select the answer value\n",
        "    answer = all_data_cleaned.loc[index, 'answer']\n",
        "\n",
        "    # Create filter for the question catalogue\n",
        "    filter = question_catalogue_clean['question'] == question\n",
        "\n",
        "    # Filter the question catalogue\n",
        "    question_catalogue_filtered = question_catalogue_clean[filter]\n",
        "\n",
        "    # Perform the exact match search\n",
        "    for index_q, row_q in question_catalogue_filtered.iterrows():\n",
        "      if answer==question_catalogue_filtered.loc[index_q,'answer_text']:\n",
        "        all_data_cleaned.loc[index, 'best_match'] = question_catalogue_filtered.loc[index_q, 'answer_text']\n",
        "        break  # Exit the loop if a match is found\n",
        "\n",
        "    # Check if any exact matches were found\n",
        "    if all_data_cleaned.loc[index, 'best_match']==None:\n",
        "\n",
        "      # Select the best match\n",
        "      best_match = find_closest_match(answer, question_catalogue_filtered['answer_text'].tolist())\n",
        "\n",
        "      # Write best match and matching score to DataFrame\n",
        "      all_data_cleaned.loc[index, 'best_match'] = best_match[0]\n",
        "      all_data_cleaned.loc[index, 'match_score'] = best_match[1]\n",
        "\n",
        "all_data_cleaned"
      ],
      "metadata": {
        "id": "LI0umImp5ROx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###check that the matches were done correctly "
      ],
      "metadata": {
        "id": "W4ZUSq1H-f8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=all_data_cleaned[['question','answer','best_match','match_score']]\n",
        "unique_df = df.drop_duplicates(subset=['question', 'answer', 'best_match','match_score']).sort_values('match_score')\n",
        "unique_df.head(20)"
      ],
      "metadata": {
        "id": "zjDQuiCQ8BRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Matching scores threshold \n",
        "\n",
        "**Change filter_match_score until only the answers we want replaced are left in the filtered dataframe**"
      ],
      "metadata": {
        "id": "VZQJl5qQV3s4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## match score filter \n",
        "filter_match_score=all_data_cleaned['match_score']<=65 ##CHANGE THIS FILTER AND CHECK THE RESULTING DATAFRAME \n",
        "\n",
        "\n",
        "#check the dataframe \n",
        "all_data_cleaned[~filter_match_score]\n"
      ],
      "metadata": {
        "id": "hQwc3HEmV2p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply filter to dataframe "
      ],
      "metadata": {
        "id": "5EHiNwo6ENLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#filter dataframe \n",
        "all_data_cleaned=all_data_cleaned[~filter_match_score].copy()"
      ],
      "metadata": {
        "id": "RKBGmPZG5QTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## join dataframes "
      ],
      "metadata": {
        "id": "BvQoPW8H-q-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## join dataframes\n",
        "\n",
        "# Join the DataFrames using two columns as the join keys\n",
        "merged_df = pd.merge(all_data_cleaned,\n",
        "                     question_catalogue_clean, \n",
        "                     left_on=['question','best_match'],\n",
        "                     right_on=['question','answer_text'],\n",
        "                     how='inner')"
      ],
      "metadata": {
        "id": "4TRHe8xP0AJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe=merged_df[['created_at',\n",
        "                          'question',\n",
        "                          'user_number',\n",
        "                          'answer',\n",
        "                          'user_mail',\n",
        "                          'answer_value']]\n",
        "\n",
        "final_dataframe"
      ],
      "metadata": {
        "id": "WuQ6-Y9X_TLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save final dataframe "
      ],
      "metadata": {
        "id": "hOFWZ_zU_-U3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### overwrite\n",
        "* Its the first time runing the script\n",
        "* We want to make the dataframe again\n",
        "when the data here is of all the log files (we process the entire folder) and "
      ],
      "metadata": {
        "id": "hioEYI7idD2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" DELETE THIS ROW IF YOU WANT TO OVERRWRITE \n",
        "\n",
        "final_dataframe.to_csv(f'/content/drive/My Drive/ SV9001 Landbot data extraction automation/{folder}/data_processed/vcs{vcs_number}_final.csv')\n",
        "\n",
        "\"\"\" ## DELETE THIS ROW IF YOU WANT TO OVERRWRITE "
      ],
      "metadata": {
        "id": "QSd9N1tA_zyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Append \n",
        "* should be used when we want to add data partially ( for example we already have a data frame made with this script  and we get new data from landbot)\n"
      ],
      "metadata": {
        "id": "v0A0g3WadBPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" ## DELETE THIS ROW IF YOU WANT TO APPEND\n",
        "\n",
        "\n",
        "# Check if the CSV file exists\n",
        "if os.path.isfile(f'/content/drive/My Drive/ SV9001 Landbot data extraction automation/{folder}/data_processed/vcs{vcs_number}_final.csv'):\n",
        "    # Read the existing CSV file into a dataframe\n",
        "    existing_dataframe = pd.read_csv(f'/content/drive/My Drive/ SV9001 Landbot data extraction automation/{folder}/data_processed/vcs{vcs_number}_final.csv')\n",
        "else:\n",
        "    # Print an error message and exit the script\n",
        "    print(f\"File not found , is this the first time running this script for this folder ?\")\n",
        "    exit()\n",
        "\n",
        "# Append the final_dataframe to the existing dataframe\n",
        "appended_dataframe = existing_dataframe.append(final_dataframe)\n",
        "\n",
        "# Write the appended dataframe to the CSV file\n",
        "appended_dataframe.to_csv(f'/content/drive/My Drive/ SV9001 Landbot data extraction automation/{folder}/data_processed/vcs{vcs_number}_final.csv')\n",
        "\n",
        "\"\"\" ## DELETE THIS ROW IF YOU WANT TO APPEND"
      ],
      "metadata": {
        "id": "1c543EGXdTYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uVvBhszOjcn9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}